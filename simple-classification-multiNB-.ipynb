{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[392   2]\n",
      " [ 83 168]]\n",
      "f1-score:   0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       394\n",
      "           1       0.99      0.67      0.80       251\n",
      "\n",
      "    accuracy                           0.87       645\n",
      "   macro avg       0.91      0.83      0.85       645\n",
      "weighted avg       0.89      0.87      0.86       645\n",
      "\n",
      "'sun and moon and orbit' => sci.space\n",
      "'nasa is fake' => sci.space\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"getting vategories\"\"\"\n",
    "categories = ['talk.religion.misc','sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "#fecthing tarinign data\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train= fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove= remove)\n",
    "\n",
    "#fecthing test data\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove= remove)\n",
    "\n",
    "x_train = twenty_train.data\n",
    "y_train = twenty_train.target\n",
    "\n",
    "x_test = twenty_test.data\n",
    "y_test = twenty_test.target\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, \n",
    "                                 stop_words='english')\n",
    "\n",
    "x_train_v = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_v, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "score = metrics.f1_score(y_test, pred)\n",
    "print(\"f1-score:   %0.3f\" % score)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "\n",
    "new_word = ['sun and moon and orbit', 'nasa is fake']\n",
    "w = vectorizer.transform(new_word)\n",
    "predicted = clf.predict(w)\n",
    "for doc, category in zip(new_word, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 18152)\n",
      "(970,)\n",
      "(1, 970)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=StandardScaler(copy=True, with_mean=False, with_std=True).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-f264dc432632>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \"\"\"\n\u001b[1;32m--> 609\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    547\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=StandardScaler(copy=True, with_mean=False, with_std=True).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"getting vategories\"\"\"\n",
    "categories = ['talk.religion.misc','sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "#fecthing tarinign data\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train= fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove= remove)\n",
    "\n",
    "#fecthing test data\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove= remove)\n",
    "\n",
    "x_train = twenty_train.data\n",
    "y_train = twenty_train.target\n",
    "\n",
    "x_test = twenty_test.data\n",
    "y_test = twenty_test.target\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, \n",
    "                                 stop_words='english')\n",
    "\n",
    "x_train_v = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "print(x_train_v.shape)\n",
    "print(y_train.shape)\n",
    "yy = np.array(y_train).reshape(1,-1)\n",
    "print(yy.shape)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "x_train_v = scaler.fit(x_train_v)\n",
    "x_test = scaler.fit(x_test)\n",
    "\n",
    "y_t = scaler.fit_transform(yy)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_v, y_t)\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "score = metrics.f1_score(y_test, pred)\n",
    "print(\"f1-score:   %0.3f\" % score)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "\n",
    "new_word = ['sun and moon and orbit', 'nasa is fake']\n",
    "w = vectorizer.transform(new_word)\n",
    "predicted = clf.predict(w)\n",
    "for doc, category in zip(new_word, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
