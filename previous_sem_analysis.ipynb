{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [14]:\n",
    "#Imports and constants \n",
    "################################################################\n",
    "\n",
    "import csv\n",
    "import graphviz\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.feature_selection import RFE,SelectKBest,chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, Imputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "#set numpy random seed for reproducible results\n",
    "np.random.seed(1234)\n",
    "#to view the whole output in the jupyter console (not only an extract)\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "#Data parameter\n",
    "#################################################################\n",
    "#File paths\n",
    "TEST_PATH ='dataset/aps_failure_test_set.csv'\n",
    "TRAIN_PATH ='dataset/aps_failure_training_set.csv'\n",
    "\n",
    "#Columns of the readed dataframe\n",
    "COLUMNS = ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n",
    "#Columns of the the final dataframe with processed histograms\n",
    "HISTOGRAMMERGEDCOLUMNS = ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000',\n",
    "                           'ah_000', 'ai_000',\n",
    "                          'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000',\n",
    "                          'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000',\n",
    "                             'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', \n",
    "                          'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', \n",
    "                          'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', \n",
    "                          'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', \n",
    "                          'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', \n",
    "                          'cj_000', 'ck_000', 'cl_000', 'cm_000', \n",
    "                          'co_000', 'cp_000', 'cq_000', 'cr_000',  \n",
    "                          'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', \n",
    "                          'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', \n",
    "                          'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', \n",
    "                          'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', \n",
    "                          'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', \n",
    "                          'ef_000', 'eg_000','ag_median','ay_median', 'az_median', 'ba_median','cn_median','cs_median','ee_median']\n",
    "\n",
    "#possible Class Labels in the dataset\n",
    "CLASS_LABELS = ['neg', 'pos']\n",
    "#Parameter to skip the first [SKIPROWS] lines in the csv files before reading into the dataframe\n",
    "SKIPROWS = 20\n",
    "\n",
    "#Histogram columns\n",
    "AG = np.array(['ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009'])\n",
    "AY = np.array(['ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009'])\n",
    "AZ = np.array(['az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009'])\n",
    "BA = np.array(['ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009'])\n",
    "CN = np.array(['cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009'])\n",
    "CS = np.array(['cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009'])\n",
    "EE = np.array(['ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009'])\n",
    "\n",
    "#NAN Data preprocessing parameter\n",
    "NaNSTRATEGY = ['mean', 'median', 'most_frequent']\n",
    "In [3]:\n",
    "#All Methods dealing with the data preprocessing \n",
    "##################################################################################\n",
    "\n",
    "#Reads the csv file from the given path as a pandas dataframe\n",
    "#returns the dataframe\n",
    "def loadDatasetWithPandas(path, skiprowsNum):\n",
    "    # Reading the raw data from csv file\n",
    "    rawData = pd.read_csv(path, skiprows=skiprowsNum)\n",
    "    # replacing the string indicating missing values with the numpy value for missing values\n",
    "    NaNProcessedData = rawData.replace({'na': np.nan}, regex=True)\n",
    "    return NaNProcessedData\n",
    "\n",
    "#creates a new dataframe from the given datafame where the different histogram bins are processed into a new feature.\n",
    "#returned dataframe is structured according to 'HISTOGRAMMERGEDCOLUMNS' variable\n",
    "def histogramProcessing(dataf):\n",
    "    data_set=dataf\n",
    "    ag_ = data_set[AG]\n",
    "    ay_ = data_set[AY]\n",
    "    az_ = data_set[AZ]\n",
    "    ba_ = data_set[BA]\n",
    "    cn_ = data_set[CN]\n",
    "    cs_ = data_set[CS]\n",
    "    ee_ = data_set[EE]\n",
    "    \n",
    "    # create new dataframe for each of the above with the mean\\n\",\n",
    "    ag_mean = ag_.mean(axis=1, skipna=True)\n",
    "    ay_mean = ay_.mean(axis=1, skipna=True)\n",
    "    az_mean = az_.mean(axis=1, skipna=True)\n",
    "    ba_mean = ba_.mean(axis=1, skipna=True)\n",
    "    cn_mean = cn_.mean(axis=1, skipna=True)\n",
    "    cs_mean = cs_.mean(axis=1, skipna=True)\n",
    "    ee_mean = ee_.mean(axis=1, skipna=True)\n",
    "\n",
    "    remaining_columns = np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.array(COLUMNS), AG), AY), AZ), BA), CN), CS), EE)\n",
    "    remaining_columns= np.concatenate([['class'],remaining_columns])\n",
    "    remaining_data = data_set[remaining_columns]\n",
    "    return pd.concat(\n",
    "        [\n",
    "            remaining_data,\n",
    "            ag_mean.rename('ag_median'),\n",
    "            ay_mean.rename('ay_median'),\n",
    "            az_mean.rename('az_median'),\n",
    "            ba_mean.rename('ba_median'),\n",
    "            cn_mean.rename('cn_median'),\n",
    "            cs_mean.rename('cs_median'),\n",
    "            ee_mean.rename('ee_median')\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "#processes the NaN values in data frame according to the provided strategy (mean, median or most_frequent) usinjg scikits Imputer.\n",
    "# returns a dataframe without any NaN values\n",
    "def processNaNInDataset(data, strategy):\n",
    "    values = data[list(COLUMNS)].values\n",
    "    imp = Imputer(missing_values='NaN', strategy=strategy, axis=0)\n",
    "    imp = imp.fit(values)\n",
    "    cleanedValues = imp.transform(values)\n",
    "    return cleanedValues\n",
    "\n",
    "#loads the csv and uses the 3 methods above to process file (loading, Nan processing)\n",
    "#returns the loaded testdatframe and trainingdataframe\n",
    "def loadDataset(strategy):\n",
    "    #Load Train Dataset\n",
    "    trainData = loadDatasetWithPandas(TRAIN_PATH, SKIPROWS)\n",
    "    #Load Test Dataset\n",
    "    testData = loadDatasetWithPandas(TEST_PATH, SKIPROWS)\n",
    "    #if no strategy for nan processing is provided just return the laoded dataframes\n",
    "    if(strategy == None):\n",
    "        return trainData, testData\n",
    "\n",
    "    #remove class column from datset to allow conversion to float datatype\n",
    "    removeClassTrain = trainData.iloc[:,1:171]\n",
    "    removeClassTest = testData.iloc[:,1:171]\n",
    "    # change datatype of the dataframe to allow computing of the mean of a column (otherwise an overflow will happen)\n",
    "    removeClassTrain = removeClassTrain.astype('float64')\n",
    "    processedTrain = processNaNInDataset(removeClassTrain,strategy)\n",
    "\n",
    "    removeClassTest = removeClassTest.astype('float64')\n",
    "    processedTest = processNaNInDataset(removeClassTest,strategy)\n",
    "   \n",
    "\n",
    "    finalTrainFrame = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(trainData.iloc[:,0]),\n",
    "                pd.DataFrame(processedTrain, columns=COLUMNS)\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    finalTestFrame = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(testData.iloc[:,0]),\n",
    "                pd.DataFrame(processedTest, columns=COLUMNS)\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    return finalTrainFrame, finalTestFrame\n",
    "In [31]:\n",
    "#This Method reduces features based the Correlation between the features.\n",
    "def CorrelationFeatureSelection(DataFrame,X,Y,flag):\n",
    "    #####Feature Selection with Co-relation####\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = X.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    # Drop features\n",
    "    # newDataFrame = X.drop(X.columns[to_drop], axis=1)\n",
    "    print(\"Features to Drop \")\n",
    "    print(to_drop)\n",
    "\n",
    "    # Creating the DataFrame with Selected Features.\n",
    "    if flag == \"Train\":\n",
    "        Readydf = DataFrame[DataFrame.columns.difference(to_drop)]\n",
    "\n",
    "\n",
    "    elif flag == \"Test\":\n",
    "        Readydf = DataFrame[DataFrame.columns.difference(to_drop)]\n",
    "\n",
    "    return Readydf\n",
    "\n",
    "\n",
    "#This Method reduces features selecting the K best features using Chi Square.\n",
    "#X = feature set, Y = class lable values, FtreNo = No of features to be selected.\n",
    "def SelectKbest(DataFrame,X,Y,FtreNo,flag):\n",
    "\n",
    "    #####Feature Extraction with Univariate Statistical Tests####\n",
    "\n",
    "    # feature extraction\n",
    "    selector = SelectKBest(score_func=chi2, k=FtreNo)\n",
    "    fit = selector.fit(X, Y)\n",
    "    # summarize scores\n",
    "    np.set_printoptions(precision=3)\n",
    "\n",
    "    #print(\"Fit Score\")\n",
    "    #print(fit.scores_)\n",
    "    features = fit.transform(X)\n",
    "\n",
    "    # get selected feature names\n",
    "    Selected_feature_names = X.columns[selector.get_support()]\n",
    "\n",
    "    #Creating the DataFrame with Selected Features.\n",
    "    if flag == \"Train\":\n",
    "        Readydf = pd.DataFrame(DataFrame, columns=Selected_feature_names)\n",
    "\n",
    "    elif flag == \"Test\":\n",
    "        Readydf = pd.DataFrame(DataFrame, columns=Selected_feature_names)\n",
    "\n",
    "    return Readydf\n",
    "\n",
    "######Feature elimination by low varience####\n",
    "def lowVarfilterfeatures(DataFrame):\n",
    "    print(\"The Std Dev are: \")\n",
    "    pd.options.display.float_format = '{:.5f}'.format\n",
    "    #print(preprocessedData)\n",
    "    print(DataFrame.std())\n",
    "    #print(DataFrame.std() > 2.90)\n",
    "    #print(DataFrame.drop(DataFrame.var()[DataFrame.var() > 2.90].index.values, axis=1))\n",
    "\n",
    "\n",
    "def filterfeatures(DataFrame, FtreSelMthd, FtreNo, flag):\n",
    "\n",
    "    #array = ImputedDataFrame.values\n",
    "    #Ftr = array[:, 0:107]\n",
    "    #ClsLbl = array[:, 107]\n",
    "\n",
    "\n",
    "    # Seperating the features from the class lable\n",
    "    X = DataFrame[DataFrame.columns.difference(['class'])]\n",
    "    Y = pd.DataFrame(DataFrame, columns=['class'])\n",
    "\n",
    "    #Based on the feature selection technique the respective method will be called.\n",
    "    if FtreSelMthd == \"Corelation\" :\n",
    "        FeatureSelected_Df = CorrelationFeatureSelection(DataFrame,X,Y,flag)\n",
    "    elif FtreSelMthd == \"SelectKBest\":\n",
    "        FeatureSelected_Df =SelectKbest(DataFrame,X,Y,FtreNo,flag)\n",
    "        \n",
    "    FeatureSelected_Df = pd.concat([FeatureSelected_Df,DataFrame[['class']]], axis = 1)\n",
    "\n",
    "    return FeatureSelected_Df\n",
    "In [5]:\n",
    "#All methods dealing with evaluation\n",
    "#################################################################################\n",
    "\n",
    "#computes/plots scikit classification report, confusion matrix and calculates the overall cost of the result using the formula provided in the dataset\n",
    "def evaluate(trueLabels, predictions):\n",
    "    classificationRep = classification_report(trueLabels, predictions)\n",
    "    print(classificationRep)\n",
    "    \n",
    "    confusionMatrix = confusion_matrix(trueLabels,predictions) \n",
    "    #print(confusionMatrix)\n",
    "    #np.set_printoptions(precision=2)\n",
    "    #Code for plotting Confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(confusionMatrix, classes=CLASS_LABELS,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(confusionMatrix, classes=CLASS_LABELS, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "    plt.show()\n",
    "    #####################\n",
    "    score = calculateOverallCostFromConfusionMatrix(confusionMatrix)\n",
    "    print('Score: ' + str(score))\n",
    "    return score\n",
    "    \n",
    "#calculates the overall cost from the given confusionMAtrix\n",
    "def calculateOverallCostFromConfusionMatrix(confusionMatrix):\n",
    "    #cost function from description\n",
    "    score = confusionMatrix[1][0] * 500 + 10*confusionMatrix[0][1]\n",
    "    return score\n",
    "\n",
    "#plots the roc curve for given true labels and the predicted results\n",
    "def plot_roc(true_lables, predictions):\n",
    "    true_labels_binarized = label_binarize(true_lables, classes=['neg', 'pos']).flatten()\n",
    "    predictions_binarized = label_binarize(predictions, classes=['neg', 'pos']).flatten()\n",
    "    false_positives, true_positives, thresholds = roc_curve(true_labels_binarized, predictions_binarized, pos_label=1)\n",
    "    roc_auc = auc(false_positives, true_positives)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positives, true_positives, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#taken from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "In [6]:\n",
    "#Loading of all datasets and possible imputations (thus data has to be loaded only once)\n",
    "####################################################################\n",
    "\n",
    "#Data, NAN not processed (rows with empty values removed)\n",
    "trainSet, testSet = loadDataset(None)\n",
    "trainSet.dropna(inplace=True)\n",
    "testSet.dropna(inplace=True)\n",
    "trainSet  = pd.DataFrame(trainSet)\n",
    "testSet  = pd.DataFrame(testSet)\n",
    "\n",
    "#Normal data NAN Processed (different strategys used)\n",
    "meanTrainSet, meanTestSet = loadDataset(NaNSTRATEGY[0])\n",
    "medianTrainSet, medianTestSet = loadDataset(NaNSTRATEGY[1])\n",
    "mostFrequentTrainSet, mostFrequentTestSet = loadDataset(NaNSTRATEGY[2])\n",
    "\n",
    "#Processed Histogram from normal, with NaN processed data\n",
    "meanTrainSetHist = histogramProcessing(meanTrainSet)\n",
    "meanTestSetHist = histogramProcessing(meanTestSet)\n",
    "medianTrainSetHist = histogramProcessing(medianTrainSet)\n",
    "medianTestSetHist = histogramProcessing(medianTestSet)\n",
    "mostFrequentTrainSetHist = histogramProcessing(mostFrequentTrainSet)\n",
    "mostFrequentTestSetHist = histogramProcessing(mostFrequentTestSet)\n",
    "In [32]:\n",
    "FtreSelMthd = \"SelectKBest\"\n",
    "FtreNo = 20\n",
    "\n",
    "featureSelectedMeanTrainDf = filterfeatures(meanTrainSet, FtreSelMthd, FtreNo, \"Train\")\n",
    "featureSelectedMeanTestDf = filterfeatures(meanTestSet, FtreSelMthd, FtreNo, \"Test\")\n",
    "\n",
    "featureSelectedMedianTrainDf = filterfeatures(medianTrainSet, FtreSelMthd, FtreNo, \"Train\")\n",
    "featureSelectedMedianTestDf = filterfeatures(medianTestSet, FtreSelMthd, FtreNo, \"Test\")\n",
    "\n",
    "featureSelectedFrequentTrainDf = filterfeatures(mostFrequentTrainSet, FtreSelMthd, FtreNo, \"Train\")\n",
    "featureSelectedFrequentTestDf = filterfeatures(mostFrequentTestSet, FtreSelMthd, FtreNo, \"Test\")\n",
    "In [37]:\n",
    "#Implementation of scikit Decision Tree\n",
    "###########################################################\n",
    "\n",
    "\n",
    "#Use max_depth, and min_sample leafs to prevent overfitting according to http://scikit-learn.org/stable/modules/tree.html#tree 1.10.5\n",
    "'''\n",
    "#histogram bin as feature\n",
    "classifier = DecisionTreeClassifier()#class_weight={'pos':.983, 'neg':.017},max_depth =max_depth, min_samples_leaf =min_samples_leaf)  \n",
    "classifier.fit(pd.DataFrame(data=meanTrainSet,columns=COLUMNS), pd.DataFrame(data=meanTrainSet,columns=['class']))  \n",
    "predictions = classifier.predict(pd.DataFrame(data=meanTestSet,columns=COLUMNS))  \n",
    "score = evaluate(pd.DataFrame(data=meanTestSet,columns=['class']), predictions)\n",
    "'''\n",
    "\n",
    "for i in range(5,50,5):\n",
    "    FtreSelMthd = \"SelectKBest\"\n",
    "    FtreNo = i\n",
    "\n",
    "    featureSelectedMeanTrainDf = filterfeatures(meanTrainSet, FtreSelMthd, FtreNo, \"Train\")\n",
    "    display(featureSelectedMeanTrainDf)\n",
    "    featureSelectedMeanTestDf = filterfeatures(meanTestSet, FtreSelMthd, FtreNo, \"Test\")\n",
    "\n",
    "    columnList = featureSelectedMeanTrainDf[featureSelectedMeanTrainDf.columns.difference(['class'])].columns.values\n",
    "\n",
    "    classifier = DecisionTreeClassifier(class_weight={'pos':.983, 'neg':.017},max_depth =3)  \n",
    "    classifier.fit(pd.DataFrame(data=featureSelectedMeanTrainDf,columns=columnList), pd.DataFrame(data=featureSelectedMeanTrainDf,columns=['class']))  \n",
    "    predictions = classifier.predict(pd.DataFrame(data=featureSelectedMeanTestDf,columns=columnList))  \n",
    "    score = evaluate(pd.DataFrame(data=featureSelectedMeanTestDf,columns=['class']), predictions)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#Hisotgram mean as feature\n",
    "classifier = DecisionTreeClassifier()#class_weight={'pos':.983, 'neg':.017},max_depth =max_depth, min_samples_leaf =min_samples_leaf)  \n",
    "classifier.fit(pd.DataFrame(data=meanTrainSetHist,columns=HISTOGRAMMERGEDCOLUMNS), pd.DataFrame(data=meanTrainSetHist,columns=['class']))  \n",
    "predictions = classifier.predict(pd.DataFrame(data=meanTestSetHist,columns=HISTOGRAMMERGEDCOLUMNS))  \n",
    "score = evaluate(pd.DataFrame(data=meanTestSetHist,columns=['class']), predictions)\n",
    "\n",
    "\n",
    "classifier = DecisionTreeClassifier()#class_weight={'pos':.983, 'neg':.017},max_depth =max_depth, min_samples_leaf =min_samples_leaf)  \n",
    "classifier.fit(pd.DataFrame(data=medianTrainSetHist,columns=HISTOGRAMMERGEDCOLUMNS), pd.DataFrame(data=medianTrainSetHist,columns=['class']))  \n",
    "predictions = classifier.predict(pd.DataFrame(data=medianTestSetHist,columns=HISTOGRAMMERGEDCOLUMNS))  \n",
    "score = evaluate(pd.DataFrame(data=medianTestSetHist,columns=['class']), predictions)\n",
    "\n",
    "classifier = DecisionTreeClassifier(class_weight={'pos':.983, 'neg':.017},max_depth =max_depth, min_samples_leaf =min_samples_leaf)  \n",
    "classifier.fit(pd.DataFrame(data=mostFrequentTrainSetHist,columns=HISTOGRAMMERGEDCOLUMNS), pd.DataFrame(data=mostFrequentTrainSetHist,columns=['class']))  \n",
    "predictions = classifier.predict(pd.DataFrame(data=mostFrequentTestSetHist,columns=HISTOGRAMMERGEDCOLUMNS))  \n",
    "score = evaluate(pd.DataFrame(data=mostFrequentTestSetHist,columns=['class']), predictions)\n",
    "\n",
    "\n",
    "#Printing of the decision tree\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None, class_names=CLASS_LABELS, feature_names=COLUMNS, \n",
    "                         filled=True, rounded=True,) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"DT\")\n",
    "\n",
    "'''\n",
    "bb_000\tbu_000\tbv_000\tcq_000\tdq_000\tclass\n",
    "0\t6.700214e+06\t6.700214e+06\t6.700214e+06\t6.700214e+06\t0.000000e+00\tneg\n",
    "1\t3.646660e+06\t3.646660e+06\t3.646660e+06\t3.646660e+06\t0.000000e+00\tneg\n",
    "2\t2.673338e+06\t2.673338e+06\t2.673338e+06\t2.673338e+06\t0.000000e+00\tneg\n",
    "3\t2.161400e+04\t2.161400e+04\t2.161400e+04\t2.161400e+04\t2.014000e+03\tneg\n",
    "4\t4.289260e+06\t4.289260e+06\t4.289260e+06\t4.289260e+06\t0.000000e+00\tneg\n",
    "5\t2.752812e+06\t2.752812e+06\t2.752812e+06\t2.752812e+06\t0.000000e+00\tneg\n",
    "6\t1.476400e+04\t1.476400e+04\t1.476400e+04\t1.476400e+04\t0.000000e+00\tneg\n",
    "7\t6.781222e+06\t6.781222e+06\t6.781222e+06\t6.781222e+06\t0.000000e+00\tneg\n",
    "8\t7.547346e+06\t7.547346e+06\t7.547346e+06\t7.547346e+06\t0.000000e+00\tneg\n",
    "9\t7.167172e+06\t7.167172e+06\t7.167172e+06\t7.167172e+06\t0.000000e+00\tpos\n",
    "10\t2.544730e+06\t2.544730e+06\t2.544730e+06\t2.544730e+06\t0.000000e+00\tneg\n",
    "11\t3.941672e+06\t3.941672e+06\t3.941672e+06\t3.941672e+06\t0.000000e+00\tneg\n",
    "12\t1.637280e+05\t1.637280e+05\t1.637280e+05\t1.637280e+05\t0.000000e+00\tneg\n",
    "13\t9.745646e+06\t9.745646e+06\t9.745646e+06\t9.745646e+06\t0.000000e+00\tneg\n",
    "14\t1.533608e+06\t1.533608e+06\t1.533608e+06\t1.533608e+06\t0.000000e+00\tneg\n",
    "15\t5.891000e+04\t5.891000e+04\t5.891000e+04\t5.891000e+04\t2.396000e+03\tneg\n",
    "16\t1.211186e+07\t1.211186e+07\t1.211186e+07\t1.211186e+07\t7.345640e+06\tneg\n",
    "17\t7.885000e+04\t7.885000e+04\t7.885000e+04\t7.885000e+04\t1.702200e+04\tneg\n",
    "18\t3.856600e+04\t3.856600e+04\t3.856600e+04\t3.856600e+04\t0.000000e+00\tneg\n",
    "19\t1.021640e+05\t1.021640e+05\t1.021640e+05\t1.021640e+05\t0.000000e+00\tneg\n",
    "20\t2.846732e+06\t2.846732e+06\t2.846732e+06\t2.846732e+06\t4.985196e+06\tneg\n",
    "21\t1.010200e+04\t1.010200e+04\t1.010200e+04\t1.010200e+04\t0.000000e+00\tneg\n",
    "22\t1.379007e+07\t1.379007e+07\t1.379007e+07\t1.379007e+07\t0.000000e+00\tneg\n",
    "23\t3.810041e+07\t3.810037e+07\t3.810037e+07\t3.810037e+07\t7.328959e+07\tpos\n",
    "24\t4.618048e+06\t4.618048e+06\t4.618048e+06\t4.618048e+06\t0.000000e+00\tneg\n",
    "25\t2.302530e+06\t2.302530e+06\t2.302530e+06\t2.302530e+06\t0.000000e+00\tneg\n",
    "26\t8.846680e+05\t8.846680e+05\t8.846680e+05\t8.846680e+05\t0.000000e+00\tneg\n",
    "27\t3.657128e+06\t3.657128e+06\t3.657128e+06\t3.657128e+06\t0.000000e+00\tneg\n",
    "28\t1.202580e+05\t1.202580e+05\t1.202580e+05\t1.202580e+05\t0.000000e+00\tneg\n",
    "29\t1.339568e+06\t1.339568e+06\t1.339568e+06\t1.339568e+06\t0.000000e+00\tneg\n",
    "30\t5.862092e+06\t5.862092e+06\t5.862092e+06\t5.862092e+06\t0.000000e+00\tneg\n",
    "31\t1.088980e+05\t1.088980e+05\t1.088980e+05\t1.088980e+05\t0.000000e+00\tneg\n",
    "32\t1.941192e+06\t1.941192e+06\t1.941192e+06\t1.941192e+06\t0.000000e+00\tneg\n",
    "33\t3.311044e+06\t3.311044e+06\t3.311044e+06\t3.311044e+06\t0.000000e+00\tneg\n",
    "34\t6.325600e+04\t6.325600e+04\t6.325600e+04\t6.325600e+04\t4.022000e+03\tneg\n",
    "35\t1.139480e+05\t1.139480e+05\t1.139480e+05\t1.139480e+05\t0.000000e+00\tneg\n",
    "36\t5.043418e+06\t5.043418e+06\t5.043418e+06\t5.043418e+06\t0.000000e+00\tneg\n",
    "37\t4.109878e+06\t4.109878e+06\t4.109878e+06\t4.109878e+06\t4.529375e+06\tneg\n",
    "38\t1.023440e+05\t1.023440e+05\t1.023440e+05\t1.023440e+05\t0.000000e+00\tneg\n",
    "39\t2.066414e+06\t2.066414e+06\t2.066414e+06\t2.066414e+06\t2.826020e+06\tneg\n",
    "40\t9.666000e+03\t9.666000e+03\t9.666000e+03\t9.666000e+03\t1.464000e+03\tneg\n",
    "41\t1.915990e+06\t1.915990e+06\t1.915990e+06\t1.915990e+06\t0.000000e+00\tneg\n",
    "42\t1.858140e+05\t1.858140e+05\t1.858140e+05\t1.858140e+05\t0.000000e+00\tneg\n",
    "43\t1.822600e+04\t1.822600e+04\t1.822600e+04\t1.822600e+04\t3.140000e+02\tneg\n",
    "44\t5.283528e+06\t5.283528e+06\t5.283528e+06\t5.283528e+06\t0.000000e+00\tneg\n",
    "45\t1.221820e+05\t1.221820e+05\t1.221820e+05\t1.221820e+05\t0.000000e+00\tneg\n",
    "46\t6.095632e+06\t6.095632e+06\t6.095632e+06\t6.095632e+06\t0.000000e+00\tneg\n",
    "47\t1.377600e+04\t1.377600e+04\t1.377600e+04\t1.377600e+04\t0.000000e+00\tneg\n",
    "48\t2.903060e+06\t2.903060e+06\t2.903060e+06\t2.903060e+06\t0.000000e+00\tneg\n",
    "49\t4.382426e+06\t4.382426e+06\t4.382426e+06\t4.382426e+06\t0.000000e+00\tneg\n",
    "50\t1.306540e+05\t1.306540e+05\t1.306540e+05\t1.306540e+05\t2.092800e+04\tneg\n",
    "51\t4.627600e+04\t4.627600e+04\t4.627600e+04\t4.627600e+04\t1.972000e+03\tneg\n",
    "52\t2.485912e+06\t2.485912e+06\t2.485912e+06\t2.485912e+06\t0.000000e+00\tneg\n",
    "53\t1.956400e+04\t1.956400e+04\t1.956400e+04\t1.956400e+04\t6.280000e+02\tneg\n",
    "54\t4.009948e+06\t4.009948e+06\t4.009948e+06\t4.009948e+06\t0.000000e+00\tneg\n",
    "55\t2.612306e+06\t2.612306e+06\t2.612306e+06\t2.612306e+06\t0.000000e+00\tneg\n",
    "56\t4.526177e+06\t4.515325e+06\t4.515325e+06\t4.515325e+06\t4.529375e+06\tneg\n",
    "57\t2.099600e+04\t2.099600e+04\t2.099600e+04\t2.099600e+04\t8.620000e+02\tneg\n",
    "58\t1.923400e+04\t1.923400e+04\t1.923400e+04\t1.923400e+04\t0.000000e+00\tneg\n",
    "59\t4.131540e+05\t4.131540e+05\t4.131540e+05\t4.131540e+05\t5.600000e+02\tneg\n",
    "60\t4.526177e+06\t4.515325e+06\t4.515325e+06\t4.515325e+06\t0.000000e+00\tpos\n",
    "61\t2.014564e+06\t2.014564e+06\t2.014564e+06\t2.014564e+06\t0.000000e+00\tneg\n",
    "62\t2.214628e+06\t2.214628e+06\t2.214628e+06\t2.214628e+06\t0.000000e+00\tneg\n",
    "63\t2.866270e+06\t2.866270e+06\t2.866270e+06\t2.866270e+06\t0.000000e+00\tneg\n",
    "64\t2.349256e+06\t2.349256e+06\t2.349256e+06\t2.349256e+06\t0.000000e+00\tneg\n",
    "65\t2.914632e+06\t2.914632e+06\t2.914632e+06\t2.914632e+06\t0.000000e+00\tneg\n",
    "66\t2.823810e+06\t2.823810e+06\t2.823810e+06\t2.823810e+06\t0.000000e+00\tneg\n",
    "67\t1.016740e+05\t1.016740e+05\t1.016740e+05\t1.016740e+05\t2.414200e+04\tneg\n",
    "68\t1.573600e+04\t1.573600e+04\t1.573600e+04\t1.573600e+04\t3.000000e+02\tneg\n",
    "69\t2.914718e+06\t2.914718e+06\t2.914718e+06\t2.914718e+06\t0.000000e+00\tneg\n",
    "70\t2.987100e+06\t2.987100e+06\t2.987100e+06\t2.987100e+06\t0.000000e+00\tneg\n",
    "71\t2.412380e+05\t2.412380e+05\t2.412380e+05\t2.412380e+05\t4.602560e+05\tneg\n",
    "72\t3.485000e+05\t3.485000e+05\t3.485000e+05\t3.485000e+05\t4.529375e+06\tneg\n",
    "73\t6.886766e+06\t6.886766e+06\t6.886766e+06\t6.886766e+06\t1.939267e+07\tneg\n",
    "74\t3.498004e+06\t3.498004e+06\t3.498004e+06\t3.498004e+06\t2.846399e+08\tneg\n",
    "75\t5.374914e+06\t5.374914e+06\t5.374914e+06\t5.374914e+06\t0.000000e+00\tneg\n",
    "76\t2.088650e+06\t2.088650e+06\t2.088650e+06\t2.088650e+06\t0.000000e+00\tneg\n",
    "77\t1.722940e+05\t1.722940e+05\t1.722940e+05\t1.722940e+05\t0.000000e+00\tneg\n",
    "78\t1.098240e+05\t1.098240e+05\t1.098240e+05\t1.098240e+05\t0.000000e+00\tneg\n",
    "79\t3.380020e+06\t3.380020e+06\t3.380020e+06\t3.380020e+06\t0.000000e+00\tneg\n",
    "80\t2.972948e+06\t2.972948e+06\t2.972948e+06\t2.972948e+06\t0.000000e+00\tneg\n",
    "81\t8.303800e+04\t8.303800e+04\t8.303800e+04\t8.303800e+04\t0.000000e+00\tneg\n",
    "82\t1.393820e+05\t1.393820e+05\t1.393820e+05\t1.393820e+05\t6.634000e+03\tneg\n",
    "83\t2.038600e+04\t2.038600e+04\t2.038600e+04\t2.038600e+04\t2.400000e+02\tneg\n",
    "84\t2.011600e+04\t2.011600e+04\t2.011600e+04\t2.011600e+04\t1.228000e+03\tneg\n",
    "85\t8.357000e+04\t8.357000e+04\t8.357000e+04\t8.357000e+04\t0.000000e+00\tneg\n",
    "86\t1.421878e+07\t1.421878e+07\t1.421878e+07\t1.421878e+07\t4.529375e+06\tneg\n",
    "87\t1.322800e+05\t1.322800e+05\t1.322800e+05\t1.322800e+05\t0.000000e+00\tneg\n",
    "88\t5.203200e+04\t5.203200e+04\t5.203200e+04\t5.203200e+04\t0.000000e+00\tneg\n",
    "89\t1.842540e+05\t1.842540e+05\t1.842540e+05\t1.842540e+05\t0.000000e+00\tneg\n",
    "90\t9.974600e+04\t9.974600e+04\t9.974600e+04\t9.974600e+04\t0.000000e+00\tneg\n",
    "91\t1.519746e+06\t1.519746e+06\t1.519746e+06\t1.519746e+06\t0.000000e+00\tneg\n",
    "92\t3.138852e+06\t3.138852e+06\t3.138852e+06\t3.138852e+06\t0.000000e+00\tneg\n",
    "93\t8.452086e+06\t8.452086e+06\t8.452086e+06\t8.452086e+06\t0.000000e+00\tneg\n",
    "94\t3.011846e+06\t3.011846e+06\t3.011846e+06\t3.011846e+06\t0.000000e+00\tneg\n",
    "95\t2.515250e+06\t2.515250e+06\t2.515250e+06\t2.515250e+06\t0.000000e+00\tneg\n",
    "96\t8.140320e+05\t8.140320e+05\t8.140320e+05\t8.140320e+05\t3.715340e+05\tneg\n",
    "97\t2.698290e+06\t2.698290e+06\t2.698290e+06\t2.698290e+06\t0.000000e+00\tneg\n",
    "98\t2.186022e+06\t2.186022e+06\t2.186022e+06\t2.186022e+06\t0.000000e+00\tneg\n",
    "99\t2.567858e+06\t2.567858e+06\t2.567858e+06\t2.567858e+06\t0.000000e+00\tneg\n",
    "100\t1.565900e+05\t1.565900e+05\t1.565900e+05\t1.565900e+05\t0.000000e+00\tneg\n",
    "101\t5.206532e+06\t5.206532e+06\t5.206532e+06\t5.206532e+06\t0.000000e+00\tneg\n",
    "102\t1.607000e+04\t1.607000e+04\t1.607000e+04\t1.607000e+04\t0.000000e+00\tneg\n",
    "103\t4.056980e+05\t4.056980e+05\t4.056980e+05\t4.056980e+05\t1.354320e+05\tneg\n",
    "104\t1.226086e+07\t1.226086e+07\t1.226086e+07\t1.226086e+07\t4.529375e+06\tneg\n",
    "105\t1.720160e+05\t1.720160e+05\t1.720160e+05\t1.720160e+05\t0.000000e+00\tneg\n",
    "106\t3.700544e+06\t3.700544e+06\t3.700544e+06\t3.700544e+06\t7.216672e+06\tneg\n",
    "107\t1.825408e+06\t1.825408e+06\t1.825408e+06\t1.825408e+06\t0.000000e+00\tneg\n",
    "108\t5.790200e+04\t5.790200e+04\t5.790200e+04\t5.790200e+04\t7.280000e+02\tneg\n",
    "109\t2.441600e+04\t2.441600e+04\t2.441600e+04\t2.441600e+04\t7.800000e+01\tneg\n",
    "110\t1.833200e+04\t1.833200e+04\t1.833200e+04\t1.833200e+04\t1.398000e+03\tneg\n",
    "111\t1.373317e+07\t1.373317e+07\t1.373317e+07\t1.373317e+07\t4.529375e+06\tneg\n",
    "112\t3.640478e+06\t3.640478e+06\t3.640478e+06\t3.640478e+06\t0.000000e+00\tneg\n",
    "113\t2.635510e+06\t2.635510e+06\t2.635510e+06\t2.635510e+06\t0.000000e+00\tneg\n",
    "114\t2.649982e+06\t2.649982e+06\t2.649982e+06\t2.649982e+06\t0.000000e+00\tneg\n",
    "115\t4.692868e+07\t4.692868e+07\t4.692868e+07\t4.692868e+07\t4.529375e+06\tpos\n",
    "116\t1.039620e+05\t1.039620e+05\t1.039620e+05\t1.039620e+05\t0.000000e+00\tneg\n",
    "117\t1.696600e+04\t1.696600e+04\t1.696600e+04\t1.696600e+04\t0.000000e+00\tneg\n",
    "118\t2.407712e+06\t2.407712e+06\t2.407712e+06\t2.407712e+06\t0.000000e+00\tneg\n",
    "119\t1.946380e+05\t1.946380e+05\t1.946380e+05\t1.946380e+05\t0.000000e+00\tneg\n",
    "120\t7.593800e+04\t7.593800e+04\t7.593800e+04\t7.593800e+04\t0.000000e+00\tneg\n",
    "121\t8.989374e+06\t8.989374e+06\t8.989374e+06\t8.989374e+06\t4.529375e+06\tneg\n",
    "122\t2.090000e+04\t2.090000e+04\t2.090000e+04\t2.090000e+04\t1.212000e+03\tneg\n",
    "123\t4.865336e+06\t4.865336e+06\t4.865336e+06\t4.865336e+06\t0.000000e+00\tneg\n",
    "124\t6.173314e+06\t6.173314e+06\t6.173314e+06\t6.173314e+06\t0.000000e+00\tneg\n",
    "125\t7.999200e+04\t7.999200e+04\t7.999200e+04\t7.999200e+04\t0.000000e+00\tneg\n",
    "126\t1.776110e+06\t1.776110e+06\t1.776110e+06\t1.776110e+06\t4.529375e+06\tneg\n",
    "127\t5.517820e+05\t5.517820e+05\t5.517820e+05\t5.517820e+05\t0.000000e+00\tneg\n",
    "128\t6.700650e+06\t6.700650e+06\t6.700650e+06\t6.700650e+06\t0.000000e+00\tneg\n",
    "129\t7.280180e+05\t7.280180e+05\t7.280180e+05\t7.280180e+05\t4.529375e+06\tneg\n",
    "130\t1.013800e+04\t1.013800e+04\t1.013800e+04\t1.013800e+04\t4.162000e+03\tneg\n",
    "131\t9.947600e+04\t9.947600e+04\t9.947600e+04\t9.947600e+04\t0.000000e+00\tneg\n",
    "132\t1.247580e+06\t1.247580e+06\t1.247580e+06\t1.247580e+06\t4.956009e+07\tneg\n",
    "133\t9.097800e+04\t9.097800e+04\t9.097800e+04\t9.097800e+04\t2.352800e+04\tneg\n",
    "134\t2.461180e+05\t2.461180e+05\t2.461180e+05\t2.461180e+05\t0.000000e+00\tneg\n",
    "135\t8.529151e+07\t4.515325e+06\t4.515325e+06\t4.515325e+06\t4.529375e+06\tpos\n",
    "136\t7.361919e+07\t7.361919e+07\t7.361919e+07\t7.361919e+07\t0.000000e+00\tneg\n",
    "137\t7.981600e+04\t7.981600e+04\t7.981600e+04\t7.981600e+04\t0.000000e+00\tneg\n",
    "138\t5.876386e+06\t5.876386e+06\t5.876386e+06\t5.876386e+06\t0.000000e+00\tneg\n",
    "139\t2.766320e+05\t2.766320e+05\t2.766320e+05\t2.766320e+05\t1.354800e+04\tneg\n",
    "140\t8.886502e+07\t8.886502e+07\t8.886502e+07\t8.886502e+07\t4.529375e+06\tneg\n",
    "141\t1.836480e+05\t1.836480e+05\t1.836480e+05\t1.836480e+05\t0.000000e+00\tneg\n",
    "142\t2.158680e+07\t2.158680e+07\t2.158680e+07\t2.158680e+07\t0.000000e+00\tneg\n",
    "143\t1.680298e+07\t1.680298e+07\t1.680298e+07\t1.680298e+07\t0.000000e+00\tneg\n",
    "144\t7.795200e+04\t7.795200e+04\t7.795200e+04\t7.795200e+04\t0.000000e+00\tneg\n",
    "145\t5.080400e+04\t5.080400e+04\t5.080400e+04\t5.080400e+04\t0.000000e+00\tneg\n",
    "146\t2.562200e+05\t2.562200e+05\t2.562200e+05\t2.562200e+05\t2.226000e+03\tneg\n",
    "147\t3.623564e+06\t3.623564e+06\t3.623564e+06\t3.623564e+06\t0.000000e+00\tneg\n",
    "148\t2.690508e+06\t2.690508e+06\t2.690508e+06\t2.690508e+06\t0.000000e+00\tneg\n",
    "149\t2.210070e+06\t2.210070e+06\t2.210070e+06\t2.210070e+06\t0.000000e+00\tneg\n",
    "150\t7.803480e+05\t7.803480e+05\t7.803480e+05\t7.803480e+05\t0.000000e+00\tneg\n",
    "151\t1.881986e+06\t1.881986e+06\t1.881986e+06\t1.881986e+06\t4.529375e+06\tneg\n",
    "152\t3.580642e+06\t3.580642e+06\t3.580642e+06\t3.580642e+06\t0.000000e+00\tneg\n",
    "153\t2.053722e+06\t2.053722e+06\t2.053722e+06\t2.053722e+06\t4.529375e+06\tneg\n",
    "154\t4.958228e+06\t4.958228e+06\t4.958228e+06\t4.958228e+06\t0.000000e+00\tneg\n",
    "155\t1.619280e+05\t1.619280e+05\t1.619280e+05\t1.619280e+05\t0.000000e+00\tneg\n",
    "156\t1.226902e+08\t1.226902e+08\t1.226902e+08\t1.226902e+08\t1.341170e+08\tpos\n",
    "157\t2.157828e+06\t2.157828e+06\t2.157828e+06\t2.157828e+06\t0.000000e+00\tneg\n",
    "158\t2.841400e+04\t2.841400e+04\t2.841400e+04\t2.841400e+04\t8.440000e+02\tneg\n",
    "159\t1.288260e+05\t1.288260e+05\t1.288260e+05\t1.288260e+05\t0.000000e+00\tneg\n",
    "160\t3.179322e+06\t3.179322e+06\t3.179322e+06\t3.179322e+06\t0.000000e+00\tneg\n",
    "161\t7.063886e+06\t7.063886e+06\t7.063886e+06\t7.063886e+06\t0.000000e+00\tneg\n",
    "162\t6.502200e+04\t6.502200e+04\t6.502200e+04\t6.502200e+04\t0.000000e+00\tneg\n",
    "163\t3.128281e+07\t3.128281e+07\t3.128281e+07\t3.128281e+07\t0.000000e+00\tneg\n",
    "164\t7.790126e+06\t7.790126e+06\t7.790126e+06\t7.790126e+06\t1.579550e+07\tneg\n",
    "165\t1.148160e+05\t1.148160e+05\t1.148160e+05\t1.148160e+05\t0.000000e+00\tneg\n",
    "166\t2.227752e+06\t2.227752e+06\t2.227752e+06\t2.227752e+06\t0.000000e+00\tneg\n",
    "167\t2.280754e+06\t2.280754e+06\t2.280754e+06\t2.280754e+06\t0.000000e+00\tneg\n",
    "168\t1.827540e+05\t1.827540e+05\t1.827540e+05\t1.827540e+05\t0.000000e+00\tneg\n",
    "169\t1.547500e+05\t1.547500e+05\t1.547500e+05\t1.547500e+05\t0.000000e+00\tneg\n",
    "170\t2.618644e+06\t2.618644e+06\t2.618644e+06\t2.618644e+06\t0.000000e+00\tneg\n",
    "171\t3.152078e+06\t3.152078e+06\t3.152078e+06\t3.152078e+06\t0.000000e+00\tneg\n",
    "172\t1.433200e+05\t1.433200e+05\t1.433200e+05\t1.433200e+05\t0.000000e+00\tneg\n",
    "173\t6.874600e+04\t6.874600e+04\t6.874600e+04\t6.874600e+04\t0.000000e+00\tneg\n",
    "174\t2.740470e+06\t2.740470e+06\t2.740470e+06\t2.740470e+06\t0.000000e+00\tneg\n",
    "175\t1.291847e+07\t1.291847e+07\t1.291847e+07\t1.291847e+07\t4.529375e+06\tneg\n",
    "176\t1.783602e+06\t1.783602e+06\t1.783602e+06\t1.783602e+06\t0.000000e+00\tneg\n",
    "177\t3.325019e+07\t3.325019e+07\t3.325019e+07\t3.325019e+07\t4.536022e+06\tpos\n",
    "178\t1.797560e+05\t1.797560e+05\t1.797560e+05\t1.797560e+05\t3.379800e+04\tneg\n",
    "179\t1.108075e+07\t1.108075e+07\t1.108075e+07\t1.108075e+07\t7.053478e+06\tneg\n",
    "180\t4.079400e+04\t4.079400e+04\t4.079400e+04\t4.079400e+04\t8.080000e+03\tneg\n",
    "181\t1.236860e+05\t1.236860e+05\t1.236860e+05\t1.236860e+05\t0.000000e+00\tneg\n",
    "182\t2.710898e+06\t2.710898e+06\t2.710898e+06\t2.710898e+06\t0.000000e+00\tneg\n",
    "183\t4.545146e+06\t4.545146e+06\t4.545146e+06\t4.545146e+06\t0.000000e+00\tneg\n",
    "184\t2.295462e+06\t2.295462e+06\t2.295462e+06\t2.295462e+06\t0.000000e+00\tneg\n",
    "185\t7.509720e+06\t7.509720e+06\t7.509720e+06\t7.509720e+06\t1.440366e+07\tneg\n",
    "186\t2.128960e+05\t2.128960e+05\t2.128960e+05\t2.128960e+05\t0.000000e+00\tneg\n",
    "187\t2.484102e+06\t2.484102e+06\t2.484102e+06\t2.484102e+06\t0.000000e+00\tneg\n",
    "188\t6.905566e+06\t6.905566e+06\t6.905566e+06\t6.905566e+06\t0.000000e+00\tneg\n",
    "189\t1.706400e+04\t1.706400e+04\t1.706400e+04\t1.706400e+04\t0.000000e+00\tneg\n",
    "190\t3.017064e+06\t3.017064e+06\t3.017064e+06\t3.017064e+06\t0.000000e+00\tneg\n",
    "191\t2.485380e+05\t2.485380e+05\t2.485380e+05\t2.485380e+05\t0.000000e+00\tneg\n",
    "192\t3.262134e+06\t3.262134e+06\t3.262134e+06\t3.262134e+06\t3.796348e+06\tneg\n",
    "193\t4.745308e+06\t4.745308e+06\t4.745308e+06\t4.745308e+06\t0.000000e+00\tneg\n",
    "194\t2.782184e+06\t2.782184e+06\t2.782184e+06\t2.782184e+06\t0.000000e+00\tneg\n",
    "195\t1.315320e+05\t1.315320e+05\t1.315320e+05\t1.315320e+05\t0.000000e+00\tneg\n",
    "196\t2.451308e+06\t2.451308e+06\t2.451308e+06\t2.451308e+06\t0.000000e+00\tneg\n",
    "197\t3.949914e+06\t3.949914e+06\t3.949914e+06\t3.949914e+06\t3.975892e+06\tneg\n",
    "198\t2.424176e+06\t2.424176e+06\t2.424176e+06\t2.424176e+06\t6.179824e+06\tneg\n",
    "199\t1.434360e+05\t1.434360e+05\t1.434360e+05\t1.434360e+05\t0.000000e+00\tneg\n",
    "200\t7.482921e+07\t7.482921e+07\t7.482921e+07\t7.482921e+07\t7.967351e+07\tneg\n",
    "201\t9.689600e+04\t9.689600e+04\t9.689600e+04\t9.689600e+04\t1.465000e+04\tneg\n",
    "202\t2.633861e+07\t2.633861e+07\t2.633861e+07\t2.633861e+07\t1.996512e+07\tneg\n",
    "203\t3.657278e+06\t3.657278e+06\t3.657278e+06\t3.657278e+06\t6.352630e+06\tneg\n",
    "204\t3.502678e+06\t3.502678e+06\t3.502678e+06\t3.502678e+06\t5.706866e+06\tneg\n",
    "205\t2.202812e+06\t2.202812e+06\t2.202812e+06\t2.202812e+06\t0.000000e+00\tneg\n",
    "206\t2.317352e+06\t2.317352e+06\t2.317352e+06\t2.317352e+06\t0.000000e+00\tneg\n",
    "207\t8.004336e+06\t8.004336e+06\t8.004336e+06\t8.004336e+06\t2.450855e+07\tneg\n",
    "208\t4.064988e+06\t4.064988e+06\t4.064988e+06\t4.064988e+06\t8.264828e+06\tneg\n",
    "209\t9.633600e+04\t9.633600e+04\t9.633600e+04\t9.633600e+04\t0.000000e+00\tneg\n",
    "210\t5.332609e+07\t5.332609e+07\t5.332609e+07\t5.332609e+07\t4.529375e+06\tpos\n",
    "211\t3.790204e+06\t3.790204e+06\t3.790204e+06\t3.790204e+06\t0.000000e+00\tneg\n",
    "212\t4.718800e+04\t4.718800e+04\t4.718800e+04\t4.718800e+04\t3.600000e+02\tneg\n",
    "213\t2.277080e+05\t2.277080e+05\t2.277080e+05\t2.277080e+05\t1.002400e+04\tneg\n",
    "214\t4.957608e+06\t4.957608e+06\t4.957608e+06\t4.957608e+06\t4.529375e+06\tneg\n",
    "215\t6.787800e+04\t6.787800e+04\t6.787800e+04\t6.787800e+04\t0.000000e+00\tneg\n",
    "216\t3.199600e+04\t3.199600e+04\t3.199600e+04\t3.199600e+04\t0.000000e+00\tneg\n",
    "217\t2.487648e+06\t2.487648e+06\t2.487648e+06\t2.487648e+06\t2.695804e+06\tneg\n",
    "218\t1.689400e+04\t1.689400e+04\t1.689400e+04\t1.689400e+04\t0.000000e+00\tneg\n",
    "219\t4.835260e+05\t4.835260e+05\t4.835260e+05\t4.835260e+05\t0.000000e+00\tneg\n",
    "220\t1.086740e+05\t1.086740e+05\t1.086740e+05\t1.086740e+05\t0.000000e+00\tneg\n",
    "221\t2.109744e+06\t2.109744e+06\t2.109744e+06\t2.109744e+06\t4.529375e+06\tneg\n",
    "222\t2.613072e+06\t2.613072e+06\t2.613072e+06\t2.613072e+06\t0.000000e+00\tneg\n",
    "223\t9.609798e+06\t9.609798e+06\t9.609798e+06\t9.609798e+06\t0.000000e+00\tneg\n",
    "224\t3.828114e+06\t3.828114e+06\t3.828114e+06\t3.828114e+06\t0.000000e+00\tneg\n",
    "225\t1.008918e+07\t1.008918e+07\t1.008918e+07\t1.008918e+07\t1.851548e+07\tneg\n",
    "226\t2.797080e+06\t2.797080e+06\t2.797080e+06\t2.797080e+06\t0.000000e+00\tneg\n",
    "227\t5.867462e+06\t5.867462e+06\t5.867462e+06\t5.867462e+06\t0.000000e+00\tneg\n",
    "228\t2.007800e+04\t2.007800e+04\t2.007800e+04\t2.007800e+04\t0.000000e+00\tneg\n",
    "229\t2.895154e+06\t2.890546e+06\t2.895154e+06\t2.895154e+06\t0.000000e+00\tneg\n",
    "230\t9.082708e+06\t9.082708e+06\t9.082708e+06\t9.082708e+06\t0.000000e+00\tneg\n",
    "231\t3.456468e+06\t3.456468e+06\t3.456468e+06\t3.456468e+06\t0.000000e+00\tneg\n",
    "232\t4.137492e+06\t4.137492e+06\t4.137492e+06\t4.137492e+06\t8.115686e+06\tneg\n",
    "233\t3.620800e+04\t3.620800e+04\t3.620800e+04\t3.620800e+04\t0.000000e+00\tneg\n",
    "234\t4.474272e+06\t4.474272e+06\t4.474272e+06\t4.474272e+06\t0.000000e+00\tneg\n",
    "235\t2.829166e+06\t2.829166e+06\t2.829166e+06\t2.829166e+06\t0.000000e+00\tneg\n",
    "236\t3.395476e+06\t3.395476e+06\t3.395476e+06\t3.395476e+06\t0.000000e+00\tneg\n",
    "237\t2.429098e+06\t2.429098e+06\t2.429098e+06\t2.429098e+06\t4.529375e+06\tneg\n",
    "238\t8.503800e+04\t8.503800e+04\t8.503800e+04\t8.503800e+04\t0.000000e+00\tneg\n",
    "239\t1.827678e+06\t1.827678e+06\t1.827678e+06\t1.827678e+06\t0.000000e+00\tneg\n",
    "240\t1.438880e+05\t1.438880e+05\t1.438880e+05\t1.438880e+05\t0.000000e+00\tneg\n",
    "241\t1.203462e+06\t1.203462e+06\t1.203462e+06\t1.203462e+06\t4.529375e+06\tneg\n",
    "242\t6.598854e+06\t6.598854e+06\t6.598854e+06\t6.598854e+06\t0.000000e+00\tneg\n",
    "243\t1.746600e+05\t1.746600e+05\t1.746600e+05\t1.746600e+05\t0.000000e+00\tneg\n",
    "244\t1.736420e+05\t1.736420e+05\t1.736420e+05\t1.736420e+05\t6.348200e+04\tneg\n",
    "245\t2.014800e+04\t2.014800e+04\t2.014800e+04\t2.014800e+04\t0.000000e+00\tneg\n",
    "246\t1.521400e+05\t1.521400e+05\t1.521400e+05\t1.521400e+05\t2.245600e+04\tneg\n",
    "247\t4.700902e+06\t4.700902e+06\t4.700902e+06\t4.700902e+06\t0.000000e+00\tneg\n",
    "248\t4.526177e+06\t4.515325e+06\t4.515325e+06\t4.515325e+06\t0.000000e+00\tneg\n",
    "249\t2.675344e+06\t2.675344e+06\t2.675344e+06\t2.675344e+06\t0.000000e+00\tneg\n",
    "...\t...\t...\t...\t...\t...\t...\n",
    "59750\t4.582600e+04\t4.582600e+04\t4.582600e+04\t4.582600e+04\t4.529375e+06\tneg\n",
    "59751\t1.747800e+04\t1.747800e+04\t1.747800e+04\t1.747800e+04\t0.000000e+00\tneg\n",
    "59752\t6.905320e+05\t6.905320e+05\t6.905320e+05\t6.905320e+05\t0.000000e+00\tneg\n",
    "59753\t1.661400e+04\t1.661400e+04\t1.661400e+04\t1.661400e+04\t2.780000e+02\tneg\n",
    "59754\t2.697000e+04\t2.697000e+04\t2.697000e+04\t2.697000e+04\t0.000000e+00\tneg\n",
    "59755\t2.184400e+04\t2.184400e+04\t2.184400e+04\t2.184400e+04\t0.000000e+00\tneg\n",
    "59756\t1.252040e+05\t1.252040e+05\t1.252040e+05\t1.252040e+05\t2.616200e+04\tneg\n",
    "59757\t1.868102e+06\t1.868102e+06\t1.868102e+06\t1.868102e+06\t0.000000e+00\tneg\n",
    "59758\t7.025800e+04\t7.025800e+04\t7.025800e+04\t7.025800e+04\t0.000000e+00\tneg\n",
    "59759\t1.939400e+04\t1.939400e+04\t1.939400e+04\t1.939400e+04\t0.000000e+00\tneg\n",
    "59760\t2.362660e+06\t2.362660e+06\t2.362660e+06\t2.362660e+06\t0.000000e+00\tneg\n",
    "59761\t2.233190e+06\t2.233190e+06\t2.233190e+06\t2.233190e+06\t0.000000e+00\tneg\n",
    "59762\t3.145368e+06\t3.145368e+06\t3.145368e+06\t3.145368e+06\t0.000000e+00\tneg\n",
    "59763\t1.140973e+07\t1.140973e+07\t1.140973e+07\t1.140973e+07\t1.511409e+07\tneg\n",
    "59764\t5.114380e+06\t5.114380e+06\t5.114380e+06\t5.114380e+06\t0.000000e+00\tneg\n",
    "59765\t1.376400e+05\t1.376400e+05\t1.376400e+05\t1.376400e+05\t2.831000e+04\tneg\n",
    "59766\t7.660720e+06\t7.660720e+06\t7.660720e+06\t7.660720e+06\t7.727996e+06\tneg\n",
    "59767\t4.436870e+06\t4.436870e+06\t4.436870e+06\t4.436870e+06\t0.000000e+00\tneg\n",
    "59768\t3.017000e+04\t3.017000e+04\t3.017000e+04\t3.017000e+04\t1.752000e+03\tneg\n",
    "59769\t3.213564e+07\t3.213564e+07\t3.213564e+07\t3.213564e+07\t0.000000e+00\tpos\n",
    "59770\t8.479048e+06\t8.479048e+06\t8.479048e+06\t8.479048e+06\t0.000000e+00\tneg\n",
    "59771\t1.059200e+05\t1.059200e+05\t1.059200e+05\t1.059200e+05\t0.000000e+00\tneg\n",
    "59772\t9.367454e+06\t9.367454e+06\t9.367454e+06\t9.367454e+06\t4.529375e+06\tneg\n",
    "59773\t7.873000e+04\t7.873000e+04\t7.873000e+04\t7.873000e+04\t0.000000e+00\tneg\n",
    "59774\t1.530920e+05\t1.530920e+05\t1.530920e+05\t1.530920e+05\t0.000000e+00\tneg\n",
    "59775\t2.940468e+06\t2.940468e+06\t2.940468e+06\t2.940468e+06\t0.000000e+00\tneg\n",
    "59776\t1.434400e+05\t1.434400e+05\t1.434400e+05\t1.434400e+05\t0.000000e+00\tneg\n",
    "59777\t1.629800e+04\t1.629800e+04\t1.629800e+04\t1.629800e+04\t2.660000e+02\tneg\n",
    "59778\t2.404780e+05\t2.404780e+05\t2.404780e+05\t2.404780e+05\t0.000000e+00\tneg\n",
    "59779\t6.703800e+04\t6.703800e+04\t6.703800e+04\t6.703800e+04\t0.000000e+00\tneg\n",
    "59780\t2.435080e+06\t2.435080e+06\t2.435080e+06\t2.435080e+06\t0.000000e+00\tneg\n",
    "59781\t6.325200e+04\t6.325200e+04\t6.325200e+04\t6.325200e+04\t6.896000e+03\tneg\n",
    "59782\t2.612818e+06\t2.612818e+06\t2.612818e+06\t2.612818e+06\t0.000000e+00\tneg\n",
    "59783\t7.450200e+04\t7.450200e+04\t7.450200e+04\t7.450200e+04\t2.400000e+03\tneg\n",
    "59784\t1.774800e+04\t1.774800e+04\t1.774800e+04\t1.774800e+04\t0.000000e+00\tneg\n",
    "59785\t1.443552e+06\t1.443552e+06\t1.443552e+06\t1.443552e+06\t0.000000e+00\tneg\n",
    "59786\t3.386912e+06\t3.386912e+06\t3.386912e+06\t3.386912e+06\t0.000000e+00\tneg\n",
    "59787\t5.310428e+06\t5.310428e+06\t5.310428e+06\t5.310428e+06\t0.000000e+00\tneg\n",
    "59788\t1.032070e+07\t1.032070e+07\t1.032070e+07\t1.032070e+07\t1.184058e+07\tneg\n",
    "59789\t1.133331e+07\t1.133331e+07\t1.133331e+07\t1.133331e+07\t4.529375e+06\tneg\n",
    "59790\t2.898400e+04\t2.898400e+04\t2.898400e+04\t2.898400e+04\t7.880000e+02\tneg\n",
    "59791\t4.281934e+06\t4.281934e+06\t4.281934e+06\t4.281934e+06\t0.000000e+00\tneg\n",
    "59792\t5.793598e+06\t5.793598e+06\t5.793598e+06\t5.793598e+06\t0.000000e+00\tneg\n",
    "59793\t4.105400e+04\t4.105400e+04\t4.105400e+04\t4.105400e+04\t3.024000e+03\tneg\n",
    "59794\t1.731000e+04\t1.731000e+04\t1.731000e+04\t1.731000e+04\t6.600000e+02\tneg\n",
    "59795\t1.242390e+07\t1.242390e+07\t1.242390e+07\t1.242390e+07\t0.000000e+00\tneg\n",
    "59796\t1.337260e+05\t1.337260e+05\t1.337260e+05\t1.337260e+05\t7.518400e+04\tneg\n",
    "59797\t1.546400e+04\t1.546400e+04\t1.546400e+04\t1.546400e+04\t1.174000e+03\tneg\n",
    "59798\t2.406596e+06\t2.406596e+06\t2.406596e+06\t2.406596e+06\t0.000000e+00\tneg\n",
    "59799\t3.012812e+06\t3.012812e+06\t3.012812e+06\t3.012812e+06\t0.000000e+00\tneg\n",
    "59800\t1.324000e+04\t1.324000e+04\t1.324000e+04\t1.324000e+04\t4.040000e+02\tneg\n",
    "59801\t2.442080e+05\t2.442080e+05\t2.442080e+05\t2.442080e+05\t4.257440e+05\tneg\n",
    "59802\t1.751580e+05\t1.751580e+05\t1.751580e+05\t1.751580e+05\t0.000000e+00\tneg\n",
    "59803\t3.687116e+06\t3.687116e+06\t3.687116e+06\t3.687116e+06\t0.000000e+00\tneg\n",
    "59804\t4.070028e+06\t4.070028e+06\t4.070028e+06\t4.070028e+06\t0.000000e+00\tneg\n",
    "59805\t3.438770e+06\t3.438770e+06\t3.438770e+06\t3.438770e+06\t0.000000e+00\tneg\n",
    "59806\t4.052196e+06\t4.052196e+06\t4.052196e+06\t4.052196e+06\t0.000000e+00\tneg\n",
    "59807\t3.025200e+04\t3.025200e+04\t3.025200e+04\t3.025200e+04\t2.904000e+03\tneg\n",
    "59808\t1.227940e+05\t1.227940e+05\t1.227940e+05\t1.227940e+05\t0.000000e+00\tneg\n",
    "59809\t4.582826e+06\t4.582826e+06\t4.582826e+06\t4.582826e+06\t6.948316e+06\tneg\n",
    "59810\t4.365400e+04\t4.365400e+04\t4.365400e+04\t4.365400e+04\t1.800000e+01\tneg\n",
    "59811\t1.068860e+05\t1.068860e+05\t1.068860e+05\t1.068860e+05\t1.988400e+04\tneg\n",
    "59812\t3.262200e+04\t3.262200e+04\t3.262200e+04\t3.262200e+04\t0.000000e+00\tneg\n",
    "59813\t2.302000e+04\t2.302000e+04\t2.302000e+04\t2.302000e+04\t1.668000e+03\tneg\n",
    "59814\t1.709866e+06\t1.709866e+06\t1.709866e+06\t1.709866e+06\t0.000000e+00\tneg\n",
    "59815\t5.044416e+06\t5.044416e+06\t5.044416e+06\t5.044416e+06\t0.000000e+00\tneg\n",
    "59816\t3.254028e+06\t3.254028e+06\t3.254028e+06\t3.254028e+06\t0.000000e+00\tneg\n",
    "59817\t1.569859e+07\t1.569859e+07\t1.569859e+07\t1.569859e+07\t0.000000e+00\tneg\n",
    "59818\t1.649800e+04\t1.649800e+04\t1.649800e+04\t1.649800e+04\t2.680000e+02\tneg\n",
    "59819\t1.382800e+04\t1.382800e+04\t1.382800e+04\t1.382800e+04\t0.000000e+00\tneg\n",
    "59820\t2.686499e+07\t2.686499e+07\t2.686499e+07\t2.686499e+07\t0.000000e+00\tneg\n",
    "59821\t2.043744e+06\t2.043744e+06\t2.043744e+06\t2.043744e+06\t0.000000e+00\tneg\n",
    "59822\t1.544000e+04\t1.544000e+04\t1.544000e+04\t1.544000e+04\t0.000000e+00\tneg\n",
    "59823\t2.736000e+04\t2.736000e+04\t2.736000e+04\t2.736000e+04\t0.000000e+00\tneg\n",
    "59824\t1.253732e+06\t1.253732e+06\t1.253732e+06\t1.253732e+06\t0.000000e+00\tneg\n",
    "59825\t2.514700e+06\t2.514700e+06\t2.514700e+06\t2.514700e+06\t0.000000e+00\tneg\n",
    "59826\t8.933000e+04\t8.933000e+04\t8.933000e+04\t8.933000e+04\t3.100000e+03\tneg\n",
    "59827\t9.097952e+06\t9.097952e+06\t9.097952e+06\t9.097952e+06\t0.000000e+00\tneg\n",
    "59828\t4.248530e+06\t4.248530e+06\t4.248530e+06\t4.248530e+06\t0.000000e+00\tneg\n",
    "59829\t4.703400e+04\t4.703400e+04\t4.703400e+04\t4.703400e+04\t0.000000e+00\tneg\n",
    "59830\t1.929760e+05\t1.929760e+05\t1.929760e+05\t1.929760e+05\t0.000000e+00\tneg\n",
    "59831\t2.884326e+06\t2.884326e+06\t2.884326e+06\t2.884326e+06\t0.000000e+00\tneg\n",
    "59832\t4.727920e+05\t4.727920e+05\t4.727920e+05\t4.727920e+05\t0.000000e+00\tneg\n",
    "59833\t4.505066e+06\t4.505066e+06\t4.505066e+06\t4.505066e+06\t6.154236e+06\tneg\n",
    "59834\t1.924998e+06\t1.924998e+06\t1.924998e+06\t1.924998e+06\t0.000000e+00\tneg\n",
    "59835\t2.930000e+04\t2.930000e+04\t2.930000e+04\t2.930000e+04\t2.322000e+03\tneg\n",
    "59836\t3.244200e+04\t3.244200e+04\t3.244200e+04\t3.244200e+04\t0.000000e+00\tneg\n",
    "59837\t5.205136e+06\t5.205136e+06\t5.205136e+06\t5.205136e+06\t0.000000e+00\tneg\n",
    "59838\t3.112782e+06\t3.112782e+06\t3.112782e+06\t3.112782e+06\t0.000000e+00\tneg\n",
    "59839\t9.983000e+04\t9.983000e+04\t9.983000e+04\t9.983000e+04\t0.000000e+00\tneg\n",
    "59840\t3.265022e+06\t3.265022e+06\t3.265022e+06\t3.265022e+06\t0.000000e+00\tneg\n",
    "59841\t2.192278e+06\t2.192278e+06\t2.192278e+06\t2.192278e+06\t0.000000e+00\tneg\n",
    "59842\t2.614992e+06\t2.614992e+06\t2.614992e+06\t2.614992e+06\t0.000000e+00\tneg\n",
    "59843\t1.440904e+07\t1.440904e+07\t1.440904e+07\t1.440904e+07\t1.203186e+07\tneg\n",
    "59844\t2.458560e+05\t2.458560e+05\t2.458560e+05\t2.458560e+05\t0.000000e+00\tneg\n",
    "59845\t6.852994e+06\t6.852994e+06\t6.852994e+06\t6.852994e+06\t0.000000e+00\tneg\n",
    "59846\t3.137617e+07\t3.137617e+07\t3.137617e+07\t3.137617e+07\t4.529375e+06\tneg\n",
    "59847\t1.375020e+05\t1.375020e+05\t1.375020e+05\t1.375020e+05\t4.529375e+06\tneg\n",
    "59848\t2.936972e+06\t2.936972e+06\t2.936972e+06\t2.936972e+06\t0.000000e+00\tneg\n",
    "59849\t1.474030e+06\t1.474030e+06\t1.474030e+06\t1.474030e+06\t0.000000e+00\tneg\n",
    "59850\t3.924588e+06\t3.924588e+06\t3.924588e+06\t3.924588e+06\t0.000000e+00\tneg\n",
    "59851\t2.506528e+06\t2.506528e+06\t2.506528e+06\t2.506528e+06\t0.000000e+00\tneg\n",
    "59852\t1.299400e+04\t1.299400e+04\t1.299400e+04\t1.299400e+04\t1.560000e+02\tneg\n",
    "59853\t2.845438e+06\t2.845438e+06\t2.845438e+06\t2.845438e+06\t0.000000e+00\tneg\n",
    "59854\t5.180422e+06\t5.180422e+06\t5.180422e+06\t5.180422e+06\t0.000000e+00\tneg\n",
    "59855\t3.232606e+06\t3.232606e+06\t3.232606e+06\t3.232606e+06\t5.403664e+06\tneg\n",
    "59856\t3.327720e+06\t3.327720e+06\t3.327720e+06\t3.327720e+06\t0.000000e+00\tneg\n",
    "59857\t5.206036e+06\t5.206036e+06\t5.206036e+06\t5.206036e+06\t0.000000e+00\tneg\n",
    "59858\t2.700800e+04\t2.700800e+04\t2.700800e+04\t2.700800e+04\t0.000000e+00\tneg\n",
    "59859\t5.515128e+06\t5.515128e+06\t5.515128e+06\t5.515128e+06\t0.000000e+00\tneg\n",
    "59860\t2.898202e+06\t2.898202e+06\t2.898202e+06\t2.898202e+06\t0.000000e+00\tneg\n",
    "59861\t2.473128e+06\t2.473128e+06\t2.473128e+06\t2.473128e+06\t0.000000e+00\tneg\n",
    "59862\t7.736400e+04\t7.736400e+04\t7.736400e+04\t7.736400e+04\t6.187200e+04\tneg\n",
    "59863\t1.861600e+04\t1.861600e+04\t1.861600e+04\t1.861600e+04\t0.000000e+00\tneg\n",
    "59864\t4.526177e+06\t4.515325e+06\t4.515325e+06\t4.515325e+06\t4.529375e+06\tneg\n",
    "59865\t4.526177e+06\t4.515325e+06\t4.515325e+06\t4.515325e+06\t2.649060e+05\tneg\n",
    "59866\t1.964519e+07\t1.964519e+07\t1.964519e+07\t1.964519e+07\t4.529375e+06\tneg\n",
    "59867\t4.219942e+06\t4.219942e+06\t4.219942e+06\t4.219942e+06\t0.000000e+00\tneg\n",
    "59868\t1.739501e+07\t1.739501e+07\t1.739501e+07\t1.739501e+07\t0.000000e+00\tneg\n",
    "59869\t2.668424e+06\t2.668424e+06\t2.668424e+06\t2.668424e+06\t0.000000e+00\tneg\n",
    "59870\t1.187716e+07\t1.187716e+07\t1.187716e+07\t1.187716e+07\t1.910598e+07\tneg\n",
    "59871\t6.715306e+06\t6.715306e+06\t6.715306e+06\t6.715306e+06\t0.000000e+00\tneg\n",
    "59872\t3.580236e+06\t3.580236e+06\t3.580236e+06\t3.580236e+06\t0.000000e+00\tneg\n",
    "59873\t1.465392e+06\t1.465392e+06\t1.465392e+06\t1.465392e+06\t0.000000e+00\tneg\n",
    "59874\t1.056060e+05\t1.056060e+05\t1.056060e+05\t1.056060e+05\t0.000000e+00\tneg\n",
    "59875\t2.727440e+05\t2.727440e+05\t2.727440e+05\t2.727440e+05\t0.000000e+00\tneg\n",
    "59876\t1.235622e+06\t1.235622e+06\t1.235622e+06\t1.235622e+06\t0.000000e+00\tneg\n",
    "59877\t3.229356e+06\t3.229356e+06\t3.229356e+06\t3.229356e+06\t3.778128e+06\tneg\n",
    "59878\t7.423000e+04\t7.423000e+04\t7.423000e+04\t7.423000e+04\t0.000000e+00\tneg\n",
    "59879\t5.388040e+05\t5.388040e+05\t5.388040e+05\t5.388040e+05\t0.000000e+00\tneg\n",
    "59880\t2.450760e+05\t2.450760e+05\t2.450760e+05\t2.450760e+05\t4.944600e+04\tneg\n",
    "59881\t2.570466e+06\t2.570466e+06\t2.570466e+06\t2.570466e+06\t0.000000e+00\tneg\n",
    "59882\t2.196298e+06\t2.196298e+06\t2.196298e+06\t2.196298e+06\t0.000000e+00\tneg\n",
    "59883\t3.865642e+06\t3.865642e+06\t3.865642e+06\t3.865642e+06\t0.000000e+00\tneg\n",
    "59884\t3.468958e+06\t3.468958e+06\t3.468958e+06\t3.468958e+06\t0.000000e+00\tneg\n",
    "59885\t1.796240e+05\t1.796240e+05\t1.796240e+05\t1.796240e+05\t5.076000e+04\tneg\n",
    "59886\t4.291350e+06\t4.291350e+06\t4.291350e+06\t4.291350e+06\t0.000000e+00\tneg\n",
    "59887\t5.194441e+07\t5.194441e+07\t5.194441e+07\t5.194441e+07\t0.000000e+00\tneg\n",
    "59888\t2.304322e+06\t2.304322e+06\t2.304322e+06\t2.304322e+06\t0.000000e+00\tneg\n",
    "59889\t2.658864e+06\t2.658864e+06\t2.658864e+06\t2.658864e+06\t0.000000e+00\tneg\n",
    "59890\t8.550200e+04\t8.550200e+04\t8.550200e+04\t8.550200e+04\t0.000000e+00\tneg\n",
    "59891\t2.850400e+04\t2.850400e+04\t2.850400e+04\t2.850400e+04\t0.000000e+00\tneg\n",
    "59892\t2.050160e+06\t2.050160e+06\t2.050160e+06\t2.050160e+06\t0.000000e+00\tneg\n",
    "59893\t2.264820e+06\t2.264820e+06\t2.264820e+06\t2.264820e+06\t0.000000e+00\tneg\n",
    "59894\t3.200192e+06\t3.200192e+06\t3.200192e+06\t3.200192e+06\t0.000000e+00\tneg\n",
    "59895\t2.060962e+06\t2.060962e+06\t2.060962e+06\t2.060962e+06\t0.000000e+00\tneg\n",
    "59896\t2.063866e+06\t2.063866e+06\t2.063866e+06\t2.063866e+06\t0.000000e+00\tneg\n",
    "59897\t2.800800e+04\t2.800800e+04\t2.800800e+04\t2.800800e+04\t8.000000e+01\tneg\n",
    "59898\t2.735590e+06\t2.735590e+06\t2.735590e+06\t2.735590e+06\t0.000000e+00\tneg\n",
    "59899\t1.088600e+04\t1.088600e+04\t1.088600e+04\t1.088600e+04\t0.000000e+00\tneg\n",
    "59900\t3.151648e+06\t3.151648e+06\t3.151648e+06\t3.151648e+06\t0.000000e+00\tneg\n",
    "59901\t1.564840e+05\t1.564840e+05\t1.564840e+05\t1.564840e+05\t0.000000e+00\tneg\n",
    "59902\t7.309986e+06\t7.309986e+06\t7.309986e+06\t7.309986e+06\t0.000000e+00\tneg\n",
    "59903\t2.372172e+06\t2.372172e+06\t2.372172e+06\t2.372172e+06\t0.000000e+00\tneg\n",
    "59904\t3.838058e+06\t3.838058e+06\t3.838058e+06\t3.838058e+06\t0.000000e+00\tneg\n",
    "59905\t4.526177e+06\t4.515325e+06\t4.515325e+06\t4.515325e+06\t4.529375e+06\tneg\n",
    "59906\t5.944400e+04\t5.944400e+04\t5.944400e+04\t5.944400e+04\t0.000000e+00\tneg\n",
    "59907\t2.272584e+06\t2.272584e+06\t2.272584e+06\t2.272584e+06\t0.000000e+00\tneg\n",
    "59908\t4.486580e+06\t4.486580e+06\t4.486580e+06\t4.486580e+06\t0.000000e+00\tneg\n",
    "59909\t3.580316e+06\t3.580316e+06\t3.580316e+06\t3.580316e+06\t0.000000e+00\tneg\n",
    "59910\t1.413160e+05\t1.413160e+05\t1.413160e+05\t1.413160e+05\t0.000000e+00\tneg\n",
    "59911\t4.240524e+07\t4.240524e+07\t4.240524e+07\t4.240524e+07\t4.529375e+06\tneg\n",
    "59912\t1.898144e+06\t1.898144e+06\t1.898144e+06\t1.898144e+06\t0.000000e+00\tneg\n",
    "59913\t2.457406e+06\t2.457406e+06\t2.457406e+06\t2.457406e+06\t0.000000e+00\tneg\n",
    "59914\t2.501560e+06\t2.501560e+06\t2.501560e+06\t2.501560e+06\t0.000000e+00\tneg\n",
    "59915\t9.929166e+06\t9.929166e+06\t9.929166e+06\t9.929166e+06\t4.529375e+06\tneg\n",
    "59916\t3.231444e+06\t3.231444e+06\t3.231444e+06\t3.231444e+06\t0.000000e+00\tneg\n",
    "59917\t2.921600e+04\t2.921600e+04\t2.921600e+04\t2.921600e+04\t0.000000e+00\tneg\n",
    "59918\t7.990000e+04\t7.990000e+04\t7.990000e+04\t7.990000e+04\t0.000000e+00\tneg\n",
    "59919\t7.921800e+04\t7.921800e+04\t7.921800e+04\t7.921800e+04\t0.000000e+00\tneg\n",
    "59920\t4.862346e+06\t4.862346e+06\t4.862346e+06\t4.862346e+06\t0.000000e+00\tneg\n",
    "59921\t5.554400e+04\t5.554400e+04\t5.554400e+04\t5.554400e+04\t0.000000e+00\tneg\n",
    "59922\t3.497098e+06\t3.497098e+06\t3.497098e+06\t3.497098e+06\t0.000000e+00\tneg\n",
    "59923\t1.180340e+05\t1.180340e+05\t1.180340e+05\t1.180340e+05\t0.000000e+00\tneg\n",
    "59924\t5.292942e+06\t5.292942e+06\t5.292942e+06\t5.292942e+06\t0.000000e+00\tneg\n",
    "59925\t3.660552e+06\t3.660552e+06\t3.660552e+06\t3.660552e+06\t0.000000e+00\tneg\n",
    "59926\t3.603322e+06\t3.603322e+06\t3.603322e+06\t3.603322e+06\t0.000000e+00\tneg\n",
    "59927\t3.201156e+06\t3.201156e+06\t3.201156e+06\t3.201156e+06\t0.000000e+00\tneg\n",
    "59928\t2.905740e+06\t2.905740e+06\t2.905740e+06\t2.905740e+06\t0.000000e+00\tneg\n",
    "59929\t5.289400e+04\t5.289400e+04\t5.289400e+04\t5.289400e+04\t1.500000e+03\tneg\n",
    "59930\t2.493248e+06\t2.493248e+06\t2.493248e+06\t2.493248e+06\t0.000000e+00\tneg\n",
    "59931\t2.877400e+04\t4.515325e+06\t4.515325e+06\t4.515325e+06\t3.838000e+03\tneg\n",
    "59932\t3.861000e+04\t3.861000e+04\t3.861000e+04\t3.861000e+04\t0.000000e+00\tneg\n",
    "59933\t5.070394e+06\t5.070394e+06\t5.070394e+06\t5.070394e+06\t0.000000e+00\tneg\n",
    "59934\t3.550020e+06\t3.550020e+06\t3.550020e+06\t3.550020e+06\t0.000000e+00\tneg\n",
    "59935\t6.784950e+06\t6.784950e+06\t6.784950e+06\t6.784950e+06\t0.000000e+00\tneg\n",
    "59936\t3.017344e+06\t3.017344e+06\t3.017344e+06\t3.017344e+06\t0.000000e+00\tneg\n",
    "59937\t2.671074e+06\t2.671074e+06\t2.671074e+06\t2.671074e+06\t0.000000e+00\tneg\n",
    "59938\t4.714260e+05\t4.714260e+05\t4.714260e+05\t4.714260e+05\t0.000000e+00\tneg\n",
    "59939\t1.920536e+07\t1.920536e+07\t1.920536e+07\t1.920536e+07\t0.000000e+00\tneg\n",
    "59940\t4.991790e+06\t4.991790e+06\t4.991790e+06\t4.991790e+06\t0.000000e+00\tneg\n",
    "59941\t1.152000e+04\t1.152000e+04\t1.152000e+04\t1.152000e+04\t0.000000e+00\tneg\n",
    "59942\t6.694400e+04\t6.694400e+04\t6.694400e+04\t6.694400e+04\t0.000000e+00\tneg\n",
    "59943\t2.392940e+06\t2.392940e+06\t2.392940e+06\t2.392940e+06\t0.000000e+00\tneg\n",
    "59944\t8.756000e+04\t8.756000e+04\t8.756000e+04\t8.756000e+04\t0.000000e+00\tneg\n",
    "59945\t1.815600e+04\t1.815600e+04\t1.815600e+04\t1.815600e+04\t2.000000e+01\tneg\n",
    "59946\t3.464200e+04\t3.464200e+04\t3.464200e+04\t3.464200e+04\t1.808000e+03\tneg\n",
    "59947\t3.397200e+04\t3.397200e+04\t3.397200e+04\t3.397200e+04\t5.960000e+03\tneg\n",
    "59948\t2.496046e+06\t2.496046e+06\t2.496046e+06\t2.496046e+06\t0.000000e+00\tneg\n",
    "59949\t3.652208e+06\t3.652208e+06\t3.652208e+06\t3.652208e+06\t0.000000e+00\tneg\n",
    "59950\t1.924358e+07\t1.924358e+07\t1.924358e+07\t1.924358e+07\t0.000000e+00\tneg\n",
    "59951\t1.068650e+07\t1.068650e+07\t1.068650e+07\t1.068650e+07\t0.000000e+00\tneg\n",
    "59952\t8.306800e+04\t8.306800e+04\t8.306800e+04\t8.306800e+04\t0.000000e+00\tneg\n",
    "59953\t2.652958e+06\t2.652958e+06\t2.652958e+06\t2.652958e+06\t0.000000e+00\tneg\n",
    "59954\t2.911796e+06\t2.911796e+06\t2.911796e+06\t2.911796e+06\t0.000000e+00\tneg\n",
    "59955\t2.535598e+06\t2.535598e+06\t2.535598e+06\t2.535598e+06\t0.000000e+00\tneg\n",
    "59956\t2.658310e+06\t2.658310e+06\t2.658310e+06\t2.658310e+06\t0.000000e+00\tneg\n",
    "59957\t6.651340e+05\t6.651340e+05\t6.651340e+05\t6.651340e+05\t0.000000e+00\tneg\n",
    "59958\t2.566324e+06\t2.566324e+06\t2.566324e+06\t2.566324e+06\t0.000000e+00\tneg\n",
    "59959\t5.484486e+06\t5.484486e+06\t5.484486e+06\t5.484486e+06\t0.000000e+00\tneg\n",
    "59960\t3.207476e+06\t3.207476e+06\t3.207476e+06\t3.207476e+06\t0.000000e+00\tneg\n",
    "59961\t3.346852e+06\t3.346852e+06\t3.346852e+06\t3.346852e+06\t0.000000e+00\tneg\n",
    "59962\t1.081380e+05\t1.081380e+05\t1.081380e+05\t1.081380e+05\t0.000000e+00\tneg\n",
    "59963\t1.097960e+05\t1.097960e+05\t1.097960e+05\t1.097960e+05\t0.000000e+00\tneg\n",
    "59964\t3.140696e+06\t3.140696e+06\t3.140696e+06\t3.140696e+06\t0.000000e+00\tneg\n",
    "59965\t1.578200e+04\t1.578200e+04\t1.578200e+04\t1.578200e+04\t7.760000e+02\tneg\n",
    "59966\t1.451600e+04\t1.451600e+04\t1.451600e+04\t1.451600e+04\t1.280000e+02\tneg\n",
    "59967\t2.019175e+07\t2.019175e+07\t2.019175e+07\t2.019175e+07\t4.529375e+06\tneg\n",
    "59968\t2.579452e+06\t2.579452e+06\t2.579452e+06\t2.579452e+06\t0.000000e+00\tneg\n",
    "59969\t5.415654e+06\t5.415654e+06\t5.415654e+06\t5.415654e+06\t0.000000e+00\tneg\n",
    "59970\t2.759800e+04\t2.759800e+04\t2.759800e+04\t2.759800e+04\t8.660000e+02\tneg\n",
    "59971\t2.937708e+06\t2.937708e+06\t2.937708e+06\t2.937708e+06\t0.000000e+00\tneg\n",
    "59972\t1.614600e+04\t1.614600e+04\t1.614600e+04\t1.614600e+04\t1.322000e+03\tneg\n",
    "59973\t4.658400e+05\t4.658400e+05\t4.658400e+05\t4.658400e+05\t0.000000e+00\tneg\n",
    "59974\t5.477608e+06\t5.477608e+06\t5.477608e+06\t5.477608e+06\t0.000000e+00\tneg\n",
    "59975\t2.652902e+06\t2.652902e+06\t2.652902e+06\t2.652902e+06\t0.000000e+00\tneg\n",
    "59976\t1.437086e+06\t1.437086e+06\t1.437086e+06\t1.437086e+06\t0.000000e+00\tneg\n",
    "59977\t1.938484e+06\t1.938484e+06\t1.938484e+06\t1.938484e+06\t2.452470e+06\tneg\n",
    "59978\t4.368640e+06\t4.368640e+06\t4.368640e+06\t4.368640e+06\t0.000000e+00\tneg\n",
    "59979\t2.636600e+04\t2.636600e+04\t2.636600e+04\t2.636600e+04\t1.620000e+02\tneg\n",
    "59980\t7.299000e+04\t7.299000e+04\t7.299000e+04\t7.299000e+04\t2.342600e+04\tneg\n",
    "59981\t1.573620e+05\t1.573620e+05\t1.573620e+05\t1.573620e+05\t0.000000e+00\tneg\n",
    "59982\t8.509880e+05\t8.509880e+05\t8.509880e+05\t8.509880e+05\t0.000000e+00\tneg\n",
    "59983\t3.076786e+06\t3.076786e+06\t3.076786e+06\t3.076786e+06\t0.000000e+00\tneg\n",
    "59984\t2.567934e+06\t2.567934e+06\t2.567934e+06\t2.567934e+06\t0.000000e+00\tneg\n",
    "59985\t4.792826e+06\t4.792826e+06\t4.792826e+06\t4.792826e+06\t0.000000e+00\tneg\n",
    "59986\t2.101800e+05\t2.101800e+05\t2.101800e+05\t2.101800e+05\t1.663000e+04\tneg\n",
    "59987\t4.131930e+06\t4.131930e+06\t4.131930e+06\t4.131930e+06\t0.000000e+00\tneg\n",
    "59988\t3.591740e+05\t3.591740e+05\t3.591740e+05\t3.591740e+05\t0.000000e+00\tneg\n",
    "59989\t4.296150e+06\t4.296150e+06\t4.296150e+06\t4.296150e+06\t0.000000e+00\tneg\n",
    "59990\t5.272338e+06\t5.272338e+06\t5.272338e+06\t5.272338e+06\t0.000000e+00\tneg\n",
    "59991\t2.506358e+06\t2.506358e+06\t2.506358e+06\t2.506358e+06\t0.000000e+00\tneg\n",
    "59992\t1.658400e+04\t1.658400e+04\t1.658400e+04\t1.658400e+04\t0.000000e+00\tneg\n",
    "59993\t1.329000e+04\t1.329000e+04\t1.329000e+04\t1.329000e+04\t0.000000e+00\tneg\n",
    "59994\t5.720200e+04\t5.720200e+04\t5.720200e+04\t5.720200e+04\t0.000000e+00\tneg\n",
    "59995\t1.084523e+07\t1.084523e+07\t1.084523e+07\t1.084523e+07\t0.000000e+00\tneg\n",
    "59996\t1.476380e+05\t1.476380e+05\t1.476380e+05\t1.476380e+05\t0.000000e+00\tneg\n",
    "59997\t4.373800e+04\t4.373800e+04\t4.373800e+04\t4.373800e+04\t4.544000e+03\tneg\n",
    "59998\t6.159728e+06\t6.159728e+06\t6.159728e+06\t6.159728e+06\t0.000000e+00\tneg\n",
    "59999\t3.076406e+06\t3.076406e+06\t3.076406e+06\t3.076406e+06\t0.000000e+00\tneg\n",
    "60000 rows  6 columns\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "<ipython-input-37-d9b9564a3755> in <module>()\n",
    "     24     classifier = DecisionTreeClassifier(class_weight={'pos':.983, 'neg':.017},max_depth =3)\n",
    "     25     classifier.fit(pd.DataFrame(data=featureSelectedMeanTrainDf,columns=columnList), pd.DataFrame(data=featureSelectedMeanTrainDf,columns=['class']))\n",
    "---> 26     predictions = classifier.predict(pd.DataFrame(data=featureSelectedMeanTestDf,columns=columnList))\n",
    "     27     score = evaluate(pd.DataFrame(data=featureSelectedMeanTestDf,columns=['class']), predictions)\n",
    "     28 \n",
    "\n",
    "~\\Anaconda3\\envs\\ATIML\\lib\\site-packages\\sklearn\\tree\\tree.py in predict(self, X, check_input)\n",
    "    410         \"\"\"\n",
    "    411         check_is_fitted(self, 'tree_')\n",
    "--> 412         X = self._validate_X_predict(X, check_input)\n",
    "    413         proba = self.tree_.predict(X)\n",
    "    414         n_samples = X.shape[0]\n",
    "\n",
    "~\\Anaconda3\\envs\\ATIML\\lib\\site-packages\\sklearn\\tree\\tree.py in _validate_X_predict(self, X, check_input)\n",
    "    371         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n",
    "    372         if check_input:\n",
    "--> 373             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n",
    "    374             if issparse(X) and (X.indices.dtype != np.intc or\n",
    "    375                                 X.indptr.dtype != np.intc):\n",
    "\n",
    "~\\Anaconda3\\envs\\ATIML\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\n",
    "    451                              % (array.ndim, estimator_name))\n",
    "    452         if force_all_finite:\n",
    "--> 453             _assert_all_finite(array)\n",
    "    454 \n",
    "    455     shape_repr = _shape_repr(array.shape)\n",
    "\n",
    "~\\Anaconda3\\envs\\ATIML\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X)\n",
    "     42             and not np.isfinite(X).all()):\n",
    "     43         raise ValueError(\"Input contains NaN, infinity\"\n",
    "---> 44                          \" or a value too large for %r.\" % X.dtype)\n",
    "     45 \n",
    "     46 \n",
    "\n",
    "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
    "In [7]:\n",
    "#Implementation of scikit Support vector Machine(Linear)\n",
    "#################################################################################\n",
    "linearSvm = svm.LinearSVC(class_weight={'pos':.983, 'neg':.017})\n",
    "\n",
    "target = pd.DataFrame(data=mostFrequentTrainSet,columns=['class'])\n",
    "\n",
    "linearSvm.fit(pd.DataFrame(data=mostFrequentTrainSet,columns=COLUMNS),target.values.ravel())  \n",
    "predictions = linearSvm.predict(pd.DataFrame(data=mostFrequentTestSet,columns=COLUMNS))  \n",
    "score = evaluate(pd.DataFrame(data=mostFrequentTestSet,columns=['class']), predictions)\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        neg       0.99      0.99      0.99     15625\n",
    "        pos       0.65      0.70      0.67       375\n",
    "\n",
    "avg / total       0.98      0.98      0.98     16000\n",
    "\n",
    "Confusion matrix, without normalization\n",
    "[[15484   141]\n",
    " [  114   261]]\n",
    "Normalized confusion matrix\n",
    "[[0.990976 0.009024]\n",
    " [0.304    0.696   ]]\n",
    "\n",
    "\n",
    "Score: 58410"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
